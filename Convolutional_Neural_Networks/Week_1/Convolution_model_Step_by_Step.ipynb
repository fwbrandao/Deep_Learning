{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages\n",
    "\n",
    "Let's first import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n",
    "- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "    \n",
    "    return X_pad\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape =\n",
      " (4, 7, 7, 2)\n",
      "x[1,1] =\n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] =\n",
      " [[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8560862be0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAACuCAYAAABUfpQYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0swshQPSzCyFA9LMLIUD0swsxf8DtS5DRn4HHEIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8560d919e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1,1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.99908945068\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "    n_H = int((n_H_prev - f + (2 * pad)) / stride + 1)\n",
    "    n_W = int((n_W_prev - f + (2 * pad)) / stride + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev[i]      # Select ith training example's padded activation\n",
    "        for h in range(n_H):     # loop over vertical axis of the output volume\n",
    "    \n",
    "    # Find the vertical start and end of the current \"slice\" (≈2 lines)        \n",
    "            vert_end = stride * h + f\n",
    "            vert_start = stride * h\n",
    "            \n",
    "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_end = stride * w + f\n",
    "                horiz_start = stride * w\n",
    "                \n",
    "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    a_slice_prev = A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    weights = W\n",
    "                    biases = b\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
    "                                        \n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.692360880758\n",
      "Z[3,2,1] =\n",
      " [ -1.28912231   2.27650251   6.61941931   0.95527176   8.25132576\n",
      "   2.31329639  13.00689405   2.34576051]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,5,7,4)\n",
    "W = np.random.randn(3,3,4,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\\n\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            vert_start = stride * h\n",
    "            vert_end = stride * h + f\n",
    "            \n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = stride * w + f\n",
    "                \n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[ 1.74481176  1.74481176  1.74481176]\n",
      "   [ 1.74481176  1.74481176  1.74481176]\n",
      "   [ 1.74481176  1.74481176  1.74481176]]\n",
      "\n",
      "  [[ 2.10025514  2.10025514  2.10025514]\n",
      "   [ 1.65980218  1.65980218  1.65980218]\n",
      "   [ 1.6924546   1.6924546   1.6924546 ]]\n",
      "\n",
      "  [[ 2.18557541  2.18557541  2.18557541]\n",
      "   [ 2.18557541  2.18557541  2.18557541]\n",
      "   [ 2.18557541  2.18557541  2.18557541]]]\n",
      "\n",
      "\n",
      " [[[ 1.19891788  1.19891788  1.19891788]\n",
      "   [ 1.2245077   1.2245077   1.2245077 ]\n",
      "   [ 1.2245077   1.2245077   1.2245077 ]]\n",
      "\n",
      "  [[ 1.96710175  1.96710175  1.96710175]\n",
      "   [ 1.96710175  1.96710175  1.96710175]\n",
      "   [ 1.62765075  1.62765075  1.62765075]]\n",
      "\n",
      "  [[ 1.96710175  1.96710175  1.96710175]\n",
      "   [ 1.96710175  1.96710175  1.96710175]\n",
      "   [ 1.62765075  1.62765075  1.62765075]]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[-0.12321458 -0.12321458 -0.12321458]\n",
      "   [-0.03614932 -0.03614932 -0.03614932]\n",
      "   [ 0.15881017  0.15881017  0.15881017]]\n",
      "\n",
      "  [[-0.06507995 -0.06507995 -0.06507995]\n",
      "   [ 0.05510967  0.05510967  0.05510967]\n",
      "   [ 0.18073215  0.18073215  0.18073215]]\n",
      "\n",
      "  [[ 0.15863244  0.15863244  0.15863244]\n",
      "   [ 0.03434459  0.03434459  0.03434459]\n",
      "   [ 0.21310407  0.21310407  0.21310407]]]\n",
      "\n",
      "\n",
      " [[[-0.0641793  -0.0641793  -0.0641793 ]\n",
      "   [-0.03984495 -0.03984495 -0.03984495]\n",
      "   [ 0.04979996  0.04979996  0.04979996]]\n",
      "\n",
      "  [[ 0.04398565  0.04398565  0.04398565]\n",
      "   [ 0.01118852  0.01118852  0.01118852]\n",
      "   [ 0.0233857   0.0233857   0.0233857 ]]\n",
      "\n",
      "  [[ 0.08033672  0.08033672  0.08033672]\n",
      "   [ 0.10404558  0.10404558  0.10404558]\n",
      "   [ 0.14703955  0.14703955  0.14703955]]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A =\n",
      " [[[[ 1.74481176  1.74481176  1.74481176]\n",
      "   [ 1.74481176  1.74481176  1.74481176]]\n",
      "\n",
      "  [[ 2.18557541  2.18557541  2.18557541]\n",
      "   [ 2.18557541  2.18557541  2.18557541]]]\n",
      "\n",
      "\n",
      " [[[ 1.19891788  1.19891788  1.19891788]\n",
      "   [ 1.2245077   1.2245077   1.2245077 ]]\n",
      "\n",
      "  [[ 1.96710175  1.96710175  1.96710175]\n",
      "   [ 1.62765075  1.62765075  1.62765075]]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 2, 2, 3)\n",
      "A =\n",
      " [[[[-0.12321458 -0.12321458 -0.12321458]\n",
      "   [ 0.15881017  0.15881017  0.15881017]]\n",
      "\n",
      "  [[ 0.15863244  0.15863244  0.15863244]\n",
      "   [ 0.21310407  0.21310407  0.21310407]]]\n",
      "\n",
      "\n",
      " [[[-0.0641793  -0.0641793  -0.0641793 ]\n",
      "   [ 0.04979996  0.04979996  0.04979996]]\n",
      "\n",
      "  [[ 0.08033672  0.08033672  0.08033672]\n",
      "   [ 0.14703955  0.14703955  0.14703955]]]]\n"
     ]
    }
   ],
   "source": [
    "# Case 2: stride of 2\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    # Retrieve information from \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters('stride')\n",
    "    pad = hparameters('pad')\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = np.random.randn(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dW = np.random.randn(f, f, n_C_prev, n_C)\n",
    "    db = np.random.randn(f, f, n_C_prev, n_C)\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i :, :, :]\n",
    "        da_prev_pad = dA_prev_pad[i :, :, :]\n",
    "        \n",
    "        \n",
    "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = stride * h\n",
    "                    vert_end = stride * h + f\n",
    "                    horiz_start = stride * w\n",
    "                    horiz_end = stride * w + f\n",
    "                    \n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d4ef7b924559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Test conv_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dA_mean =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dW_mean =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-76804da680ec>\u001b[0m in \u001b[0;36mconv_backward\u001b[0;34m(dZ, cache)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Retrieve information from \"hparameters\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stride'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "# We'll run conv_forward to initialize the 'Z' and 'cache_conv\",\n",
    "# which we'll use to test the conv_backward function\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "\n",
    "# Test conv_backward\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    \n",
    "    mask = (x == np.max(x))\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2,3)\n",
    "mask = create_mask_from_window(x)\n",
    "print('x = ', x)\n",
    "print(\"mask = \", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \n",
    "    # Retrieve dimensions from shape (≈1 line)\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix (≈1 line)\n",
    "    average = dz / (n_H * n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
    "    a = average * np.ones(shape)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[ 0.5  0.5]\n",
      " [ 0.5  0.5]]\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2,2))\n",
    "print('distributed value =', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \n",
    "    # Retrieve information from cache (≈1 line)\n",
    "    (A_prev, hparameters) = None\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
    "    stride = None\n",
    "    f = None\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = None\n",
    "    m, n_H, n_W, n_C = None\n",
    "    \n",
    "    # Initialize dA_prev with zeros (≈1 line)\n",
    "    dA_prev = None\n",
    "    \n",
    "    for i in range(None):                       # loop over the training examples\n",
    "        \n",
    "        # select training example from A_prev (≈1 line)\n",
    "        a_prev = None\n",
    "        \n",
    "        for h in range(None):                   # loop on the vertical axis\n",
    "            for w in range(None):               # loop on the horizontal axis\n",
    "                for c in range(None):           # loop over the channels (depth)\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = None\n",
    "                    vert_end = None\n",
    "                    horiz_start = None\n",
    "                    horiz_end = None\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
    "                        a_prev_slice = None\n",
    "                        # Create the mask from a_prev_slice (≈1 line)\n",
    "                        mask = None\n",
    "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += None\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                        # Get the value a from dA (≈1 line)\n",
    "                        da = None\n",
    "                        # Define the shape of the filter as fxf (≈1 line)\n",
    "                        shape = None\n",
    "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += None\n",
    "                    \n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-11d33c897a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode = max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean of dA = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-2eff5c07af3d>\u001b[0m in \u001b[0;36mpool_backward\u001b[0;34m(dA, cache, mode)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve information from cache (≈1 line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Retrieve hyperparameters from \"hparameters\" (≈2 lines)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "\n",
    "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "print()\n",
    "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "qO8ng",
   "launcher_item_id": "7XDi8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
